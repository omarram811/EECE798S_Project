[
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C1+-+Introduction+to+GenAI.pdf",
    "question": "What is the main difference between discriminative and generative AI?",
    "gold_answer": "Discriminative AI predicts labels or class boundaries, while generative AI models the data distribution to generate new content.",
    "answer": "Generative AI creates new content by learning data patterns and structures, producing novel data instances like text, images, and music. Discriminative AI focuses on classifying or labeling data, predicting outputs from given inputs, such as in spam or fraud detection.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf"
      ],
      "top1_doc": "C1+-+Introduction+to+GenAI.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 2
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 3
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 8
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 10
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 1
        }
      ]
    },
    "metrics": {
      "f1": 0.2692307692307692,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8834193348884583,
      "latency_seconds": 0.8152248000114923,
      "input_tokens": 1577,
      "output_tokens": 50,
      "total_tokens": 1627,
      "input_cost": 0.00011827499999999999,
      "output_cost": 1.4999999999999999e-05,
      "total_cost": 0.00013327499999999997
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C1+-+Introduction+to+GenAI.pdf",
    "question": "What was the technological shift that enabled modern AI agents?",
    "gold_answer": "The shift was the emergence of powerful generative models—especially transformers and LLMs—that provided agents with strong reasoning and language abilities.",
    "answer": "The technological shift that enabled modern AI agents was the increase in size, power, and capability of generative AI models and algorithms. This allowed agents to be equipped with a more powerful \"brain.\"\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf"
      ],
      "top1_doc": "C3+-+Introduction+to+Agents.pdf",
      "top1_matches_gold": false,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 0
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 0
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 5
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 1
        }
      ]
    },
    "metrics": {
      "f1": 0.3829787234042554,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8032103180885315,
      "latency_seconds": 0.7757805000001099,
      "input_tokens": 1754,
      "output_tokens": 39,
      "total_tokens": 1793,
      "input_cost": 0.00013155,
      "output_cost": 1.17e-05,
      "total_cost": 0.00014324999999999999
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C1+-+Introduction+to+GenAI.pdf",
    "question": "Name two real-world applications of generative AI discussed in the document.",
    "gold_answer": "Image generation and visual question answering.",
    "answer": "Two real-world applications of generative AI are Agentforce by Salesforce, which creates and manages autonomous agents for business operations, and the \"Agent\" mode in Cursor, which autonomously explores a codebase to complete tasks. Self-driving cars also utilize discriminative computer vision models to make decisions.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf"
      ],
      "top1_doc": "C1+-+Introduction+to+GenAI.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 3
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 4
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 8
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 1
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 0
        }
      ]
    },
    "metrics": {
      "f1": 0.0425531914893617,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.5210583806037903,
      "latency_seconds": 1.0984271000052104,
      "input_tokens": 1699,
      "output_tokens": 60,
      "total_tokens": 1759,
      "input_cost": 0.000127425,
      "output_cost": 1.7999999999999997e-05,
      "total_cost": 0.000145425
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C1+-+Introduction+to+GenAI.pdf",
    "question": "What role do transformers play in modern GenAI?",
    "gold_answer": "Transformers enable models to understand contextual relationships through attention mechanisms.",
    "answer": "The Transformer architecture, specifically the attention mechanism, revolutionized natural language understanding and generation, which enabled modern GenAI. The Transformer architecture was a breakthrough that enabled generative models to achieve their current level of power.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf"
      ],
      "top1_doc": "C1+-+Introduction+to+GenAI.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 16
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 0
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 2
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 15
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 18
        }
      ]
    },
    "metrics": {
      "f1": 0.15384615384615385,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7791181802749634,
      "latency_seconds": 0.7208523000008427,
      "input_tokens": 1722,
      "output_tokens": 42,
      "total_tokens": 1764,
      "input_cost": 0.00012915,
      "output_cost": 1.26e-05,
      "total_cost": 0.00014175
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C1+-+Introduction+to+GenAI.pdf",
    "question": "What is the definition of Generative AI according to the slides?",
    "gold_answer": "Generative AI is a field where models create new content such as text, images, audio, or video based on training data.",
    "answer": "Generative AI is a field of artificial intelligence where models can create new content, such as text, images, audio, or video, based on the data it has been trained on.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C1+-+Introduction+to+GenAI.pdf"
      ],
      "top1_doc": "C1+-+Introduction+to+GenAI.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 3
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 2
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 0
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 4
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 8
        }
      ]
    },
    "metrics": {
      "f1": 0.7999999999999999,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": true,
      "semantic_similarity": 0.9848005771636963,
      "latency_seconds": 0.627327599999262,
      "input_tokens": 1669,
      "output_tokens": 38,
      "total_tokens": 1707,
      "input_cost": 0.000125175,
      "output_cost": 1.14e-05,
      "total_cost": 0.000136575
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C2+-+Large+Language+Models.pdf",
    "question": "What makes a language model 'large'?",
    "gold_answer": "A model is considered large when it contains millions to billions of parameters stacked across many transformer layers.",
    "answer": "A large language model is characterized by a large number of parameters and a large training dataset. To have a model that contains a lot of information, we need a large number of parameters.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf"
      ],
      "top1_doc": "C2+-+Large+Language+Models.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 3
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 19
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 31
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 32
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 1
        }
      ]
    },
    "metrics": {
      "f1": 0.41025641025641024,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8307392001152039,
      "latency_seconds": 0.7370501000114018,
      "input_tokens": 1734,
      "output_tokens": 38,
      "total_tokens": 1772,
      "input_cost": 0.00013005,
      "output_cost": 1.14e-05,
      "total_cost": 0.00014145
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C2+-+Large+Language+Models.pdf",
    "question": "What were LLMs originally designed to do?",
    "gold_answer": "They were designed to perform text modeling tasks with high accuracy by predicting the next token.",
    "answer": "The original purpose of large language models was to perform traditional text tasks with high accuracy. LLMs were trained to predict text.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf"
      ],
      "top1_doc": "C2+-+Large+Language+Models.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 2
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 3
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 1
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 4
        }
      ]
    },
    "metrics": {
      "f1": 0.5,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7141737937927246,
      "latency_seconds": 0.6489129999972647,
      "input_tokens": 1775,
      "output_tokens": 26,
      "total_tokens": 1801,
      "input_cost": 0.00013312499999999997,
      "output_cost": 7.799999999999998e-06,
      "total_cost": 0.00014092499999999997
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C2+-+Large+Language+Models.pdf",
    "question": "Name one emergent behavior of LLMs shown in the slides.",
    "gold_answer": "Chain-of-thought reasoning.",
    "answer": "One emergent behavior of LLMs is solving new tasks without gradient updates, just from prompts. Other emergent behaviors include step-by-step logic, writing functional code, following instructions to use tools, and inferring others' beliefs. LLMs can also combine learned patterns in new ways.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C2+-+Large+Language+Models.pdf"
      ],
      "top1_doc": "C2+-+Large+Language+Models.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 4
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 3
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 2
        }
      ]
    },
    "metrics": {
      "f1": 0.0,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.42663174867630005,
      "latency_seconds": 0.8570945999963442,
      "input_tokens": 1778,
      "output_tokens": 58,
      "total_tokens": 1836,
      "input_cost": 0.00013335,
      "output_cost": 1.74e-05,
      "total_cost": 0.00015074999999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C2+-+Large+Language+Models.pdf",
    "question": "Why are long context windows not equivalent to real memory?",
    "gold_answer": "Long contexts only retain information within a single session and do not create persistent knowledge across tasks.",
    "answer": "Long context windows provided by new models do not solve the memory issue. They only provide an illusion of memory within a single session and lack true long-term understanding.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C6+-+Agent+Memory.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C6+-+Agent+Memory.pdf",
        "C2+-+Large+Language+Models.pdf"
      ],
      "top1_doc": "C6+-+Agent+Memory.pdf",
      "top1_matches_gold": false,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 2
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 27
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 20
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 1
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 28
        }
      ]
    },
    "metrics": {
      "f1": 0.39999999999999997,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8169965744018555,
      "latency_seconds": 0.6131471000117017,
      "input_tokens": 1734,
      "output_tokens": 34,
      "total_tokens": 1768,
      "input_cost": 0.00013005,
      "output_cost": 1.02e-05,
      "total_cost": 0.00014025
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C2+-+Large+Language+Models.pdf",
    "question": "What is the purpose of tokenization in an LLM pipeline?",
    "gold_answer": "Tokenization converts input text into tokens that the model can embed and process.",
    "answer": "Tokenization is a data cleaning technique used in LLM pre-training. It involves breaking down text into tokens, which can be as short as one character or as long as one word, using methods like Byte Pair Encoding (BPE) or SentencePiece.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf"
      ],
      "top1_doc": "C2+-+Large+Language+Models.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 30
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 29
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 14
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 17
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 2
        }
      ]
    },
    "metrics": {
      "f1": 0.20833333333333331,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8368654251098633,
      "latency_seconds": 0.8574858000065433,
      "input_tokens": 1828,
      "output_tokens": 53,
      "total_tokens": 1881,
      "input_cost": 0.0001371,
      "output_cost": 1.5899999999999997e-05,
      "total_cost": 0.000153
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C3+-+Introduction+to+Agents.pdf",
    "question": "What distinguishes an agent from a chatbot?",
    "gold_answer": "Agents take actions using tools and pursue goals, while chatbots mainly produce text responses.",
    "answer": "An agent is not just a chatbot. Unlike chatbots, agents are defined by their ability to take action and engage in goal-driven reasoning rather than simply providing conversational responses.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf"
      ],
      "top1_doc": "C3+-+Introduction+to+Agents.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 2
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 7
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 7
        }
      ]
    },
    "metrics": {
      "f1": 0.23255813953488377,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8786799907684326,
      "latency_seconds": 0.6416962000075728,
      "input_tokens": 1820,
      "output_tokens": 36,
      "total_tokens": 1856,
      "input_cost": 0.00013649999999999998,
      "output_cost": 1.0799999999999998e-05,
      "total_cost": 0.00014729999999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C3+-+Introduction+to+Agents.pdf",
    "question": "What are the five key components of an AI agent listed in the chapter?",
    "gold_answer": "Multiple LLM calls, tool use, environment interaction, a planner, and autonomy.",
    "answer": "I don't know from the course materials.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C1+-+Introduction+to+GenAI.pdf"
      ],
      "top1_doc": "C3+-+Introduction+to+Agents.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 0
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 7
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 0
        }
      ]
    },
    "metrics": {
      "f1": 0.0,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.2956664264202118,
      "latency_seconds": 0.5068809000076726,
      "input_tokens": 1872,
      "output_tokens": 11,
      "total_tokens": 1883,
      "input_cost": 0.0001404,
      "output_cost": 3.2999999999999993e-06,
      "total_cost": 0.0001437
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C3+-+Introduction+to+Agents.pdf",
    "question": "How does reinforcement learning relate to agents?",
    "gold_answer": "RL models agents by having them interact with an environment and learn through rewards.",
    "answer": "Reinforcement Learning (RL) is a way for agents to learn by trying actions and seeing what works, receiving rewards for good actions. Agents use RL to interact with their environment through trial and error to maximize rewards over time. This is inspired by how humans and animals learn from experience.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf"
      ],
      "top1_doc": "C3+-+Introduction+to+Agents.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 4
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 0
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 6
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        }
      ]
    },
    "metrics": {
      "f1": 0.3846153846153846,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8643009662628174,
      "latency_seconds": 0.7676013000018429,
      "input_tokens": 1891,
      "output_tokens": 58,
      "total_tokens": 1949,
      "input_cost": 0.000141825,
      "output_cost": 1.74e-05,
      "total_cost": 0.00015922499999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C3+-+Introduction+to+Agents.pdf",
    "question": "Why did modern LLMs enable advanced agentic systems?",
    "gold_answer": "Because LLMs provide reasoning, planning, generalization, and natural language understanding capabilities.",
    "answer": "Modern LLMs unlocked true agentic behavior because they brought language understanding and generation, chain-of-thought reasoning, generalization across domains, and multi-step planning with feedback. These capabilities allowed LLMs to transition from passive responders to adaptive cognitive engines. They are also able to follow instructions to call APIs, use calculators, and browse.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C3+-+Introduction+to+Agents.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C3+-+Introduction+to+Agents.pdf"
      ],
      "top1_doc": "C3+-+Introduction+to+Agents.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 3
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 4
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 0
        }
      ]
    },
    "metrics": {
      "f1": 0.33333333333333337,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7622348070144653,
      "latency_seconds": 0.8167859999957727,
      "input_tokens": 1849,
      "output_tokens": 68,
      "total_tokens": 1917,
      "input_cost": 0.000138675,
      "output_cost": 2.04e-05,
      "total_cost": 0.000159075
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C3+-+Introduction+to+Agents.pdf",
    "question": "What does it mean for an agent to be goal-oriented?",
    "gold_answer": "It means the agent selects actions not just to respond but to achieve a defined outcome.",
    "answer": "An agent is goal-oriented because it has a goal it aims to achieve. This is demonstrated by the agent trying actions, seeing what works (reward), and trying again to maximize rewards over time. The agent's actions are driven by its goal.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf"
      ],
      "top1_doc": "C3+-+Introduction+to+Agents.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 4
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 6
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 7
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 3
        }
      ]
    },
    "metrics": {
      "f1": 0.2978723404255319,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7505903840065002,
      "latency_seconds": 0.8089920999918832,
      "input_tokens": 1885,
      "output_tokens": 52,
      "total_tokens": 1937,
      "input_cost": 0.00014137499999999998,
      "output_cost": 1.5599999999999996e-05,
      "total_cost": 0.00015697499999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
    "question": "What are the two major components that define an agent's mind?",
    "gold_answer": "Agent persona and thinking mechanism.",
    "answer": "I don't know from the course materials.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C6+-+Agent+Memory.pdf"
      ],
      "top1_doc": "C3+-+Introduction+to+Agents.pdf",
      "top1_matches_gold": false,
      "any_match_in_topk": false,
      "chunks_used": [
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 6
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 4
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 1
        }
      ]
    },
    "metrics": {
      "f1": 0.0,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.34534451365470886,
      "latency_seconds": 0.5067694000026677,
      "input_tokens": 1857,
      "output_tokens": 11,
      "total_tokens": 1868,
      "input_cost": 0.00013927499999999998,
      "output_cost": 3.2999999999999993e-06,
      "total_cost": 0.00014257499999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
    "question": "What does temperature control in model configuration?",
    "gold_answer": "Temperature controls randomness in token selection and influences creativity versus determinism.",
    "answer": "Temperature controls the balance between safe, predictable answers and creative, novel responses. It adjusts the randomness in token selection. Low temperatures result in deterministic and focused responses, while high temperatures yield creative and diverse outputs.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf"
      ],
      "top1_doc": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 1
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 4
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 2
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 6
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 5
        }
      ]
    },
    "metrics": {
      "f1": 0.358974358974359,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8587965965270996,
      "latency_seconds": 0.7254973000090104,
      "input_tokens": 1728,
      "output_tokens": 42,
      "total_tokens": 1770,
      "input_cost": 0.00012959999999999998,
      "output_cost": 1.26e-05,
      "total_cost": 0.0001422
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
    "question": "What is a Chain-of-Thought reasoning mechanism?",
    "gold_answer": "A reasoning method where the model generates step-by-step explanations before answering.",
    "answer": "Chain of Thought breaks complex problems into smaller, logical steps to solve them more clearly. It mimics how people reason through problems gradually rather than jumping to answers. This mechanism involves step-by-step thinking.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf"
      ],
      "top1_doc": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 12
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 13
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 11
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 10
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 14
        }
      ]
    },
    "metrics": {
      "f1": 0.047619047619047616,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.6251672506332397,
      "latency_seconds": 0.9295581999904243,
      "input_tokens": 1813,
      "output_tokens": 42,
      "total_tokens": 1855,
      "input_cost": 0.00013597499999999998,
      "output_cost": 1.26e-05,
      "total_cost": 0.000148575
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
    "question": "What does a high frequency penalty encourage?",
    "gold_answer": "It encourages reduced repetition by penalizing tokens already used frequently.",
    "answer": "A high frequency penalty encourages the model to avoid repetition and promote diversity in its output. This is great for essays, articles, and research.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf"
      ],
      "top1_doc": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 3
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 4
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 27
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 32
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 33
        }
      ]
    },
    "metrics": {
      "f1": 0.12121212121212122,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.611075222492218,
      "latency_seconds": 0.6442714000004344,
      "input_tokens": 1666,
      "output_tokens": 29,
      "total_tokens": 1695,
      "input_cost": 0.00012494999999999997,
      "output_cost": 8.7e-06,
      "total_cost": 0.00013364999999999997
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
    "question": "Why do different prompts create different agent personas?",
    "gold_answer": "Because the LLM conditions its behavior on the instructions, shaping style, tone, and reasoning patterns.",
    "answer": "Prompts are used to define an agent's persona. They define the agent's role, tone, style, and behavior, which shapes how the agent interacts. For example, a prompt might define an agent as a friendly tutor or a cybersecurity expert.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf"
      ],
      "top1_doc": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 6
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 7
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 5
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 0
        }
      ]
    },
    "metrics": {
      "f1": 0.2222222222222222,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.5858221650123596,
      "latency_seconds": 24.92611699999543,
      "input_tokens": 1709,
      "output_tokens": 53,
      "total_tokens": 1762,
      "input_cost": 0.00012817499999999998,
      "output_cost": 1.5899999999999997e-05,
      "total_cost": 0.000144075
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C5+-+Agent+Tools.pdf",
    "question": "What are agent tools?",
    "gold_answer": "Functions provided to an LLM that enable actions or computations beyond the model’s internal capabilities.",
    "answer": "Tools are functions that perform actions on behalf of the AI model. These operations can have effects or require computation beyond the AI's own capabilities. A good tool complements the power of an LLM.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C5+-+Agent+Tools.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C5+-+Agent+Tools.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C5+-+Agent+Tools.pdf"
      ],
      "top1_doc": "C5+-+Agent+Tools.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 0
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 15
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 13
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 11
        }
      ]
    },
    "metrics": {
      "f1": 0.3913043478260869,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7579125165939331,
      "latency_seconds": 0.9071022999996785,
      "input_tokens": 1863,
      "output_tokens": 41,
      "total_tokens": 1904,
      "input_cost": 0.000139725,
      "output_cost": 1.2299999999999999e-05,
      "total_cost": 0.000152025
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C5+-+Agent+Tools.pdf",
    "question": "Why do agents need tools for real-time information?",
    "gold_answer": "LLMs lack up-to-date knowledge and can hallucinate without retrieving external information.",
    "answer": "Agents need tools to provide them with up-to-date data. LLMs are trained on data up to a certain point in time, so they need tools to access current information. For example, a search tool can provide real-time weather information.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C5+-+Agent+Tools.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf"
      ],
      "top1_doc": "C5+-+Agent+Tools.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 1
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 6
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 7
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 1
        }
      ]
    },
    "metrics": {
      "f1": 0.19047619047619047,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.6017387509346008,
      "latency_seconds": 1.0456378000089899,
      "input_tokens": 1820,
      "output_tokens": 52,
      "total_tokens": 1872,
      "input_cost": 0.00013649999999999998,
      "output_cost": 1.5599999999999996e-05,
      "total_cost": 0.00015209999999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C5+-+Agent+Tools.pdf",
    "question": "What are the three main characteristics of a good tool?",
    "gold_answer": "A well-defined API, isolated functionality, and deterministic behavior.",
    "answer": "The key characteristics of an agent's tools are a well-defined API (if needed) with clear input parameters and output schema, isolated functionality with a single responsibility, and deterministic behavior to ensure predictable results given valid inputs. These characteristics ensure the tool functions as intended and simplifies its use.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C5+-+Agent+Tools.pdf",
        "C5+-+Agent+Tools.pdf",
        "C5+-+Agent+Tools.pdf",
        "C5+-+Agent+Tools.pdf",
        "C5+-+Agent+Tools.pdf"
      ],
      "top1_doc": "C5+-+Agent+Tools.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 1
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 10
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 9
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 2
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 0
        }
      ]
    },
    "metrics": {
      "f1": 0.326530612244898,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.6990945339202881,
      "latency_seconds": 0.8174132999993162,
      "input_tokens": 1814,
      "output_tokens": 59,
      "total_tokens": 1873,
      "input_cost": 0.00013605,
      "output_cost": 1.7699999999999997e-05,
      "total_cost": 0.00015375
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C5+-+Agent+Tools.pdf",
    "question": "What protocol standardizes how tools communicate with LLMs?",
    "gold_answer": "The Model Context Protocol (MCP).",
    "answer": "Model Context Protocol (MCP) is the standard interface for LLMs to call tools. It defines how models declare, request, and execute actions, supporting tool schemas, parameters, and expected output formats. MCP helps avoid ambiguous or inconsistent tool calls.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C5+-+Agent+Tools.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C5+-+Agent+Tools.pdf",
        "C5+-+Agent+Tools.pdf",
        "C3+-+Introduction+to+Agents.pdf"
      ],
      "top1_doc": "C5+-+Agent+Tools.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 0
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 12
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 2
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 11
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 13
        }
      ]
    },
    "metrics": {
      "f1": 0.25,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7890849709510803,
      "latency_seconds": 3.6672421999974176,
      "input_tokens": 1786,
      "output_tokens": 50,
      "total_tokens": 1836,
      "input_cost": 0.00013395,
      "output_cost": 1.4999999999999999e-05,
      "total_cost": 0.00014895000000000002
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C5+-+Agent+Tools.pdf",
    "question": "Why do tools reduce token usage?",
    "gold_answer": "Because they return structured, concise data instead of requiring the LLM to process raw text.",
    "answer": "I don't know from the course materials.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C5+-+Agent+Tools.pdf",
        "C5+-+Agent+Tools.pdf",
        "C5+-+Agent+Tools.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C5+-+Agent+Tools.pdf"
      ],
      "top1_doc": "C5+-+Agent+Tools.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 9
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 11
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 15
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 0
        }
      ]
    },
    "metrics": {
      "f1": 0.09090909090909091,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.3350312411785126,
      "latency_seconds": 0.5977847999893129,
      "input_tokens": 1828,
      "output_tokens": 11,
      "total_tokens": 1839,
      "input_cost": 0.0001371,
      "output_cost": 3.2999999999999993e-06,
      "total_cost": 0.0001404
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C6+-+Agent+Memory.pdf",
    "question": "Why do agents need memory?",
    "gold_answer": "To maintain context across interactions, enabling continuity and personalized behavior.",
    "answer": "Agents need memory to retain and recall relevant information across time, tasks, and multiple user interactions. This allows them to remember past events and use that information to improve their behavior in the future. Memory enables agents to build a persistent internal state that evolves and informs every interaction.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf"
      ],
      "top1_doc": "C6+-+Agent+Memory.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 1
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 2
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 29
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 26
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 7
        }
      ]
    },
    "metrics": {
      "f1": 0.2040816326530612,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.6699880361557007,
      "latency_seconds": 0.8069928000040818,
      "input_tokens": 1833,
      "output_tokens": 55,
      "total_tokens": 1888,
      "input_cost": 0.000137475,
      "output_cost": 1.6499999999999998e-05,
      "total_cost": 0.000153975
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C6+-+Agent+Memory.pdf",
    "question": "What is short-term memory in an agent?",
    "gold_answer": "It stores the current conversation or task context within a single session.",
    "answer": "Short-term memory, also known as working memory, is analogous to a conversation thread or a computer's RAM. It ensures local coherence, allowing the agent to remember what was just said or done so it can respond fluently within a single session. Once the session ends, the data is lost unless saved.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf"
      ],
      "top1_doc": "C6+-+Agent+Memory.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 4
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 3
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 2
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 5
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 1
        }
      ]
    },
    "metrics": {
      "f1": 0.3018867924528301,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.6696011424064636,
      "latency_seconds": 0.8376342999981716,
      "input_tokens": 1825,
      "output_tokens": 64,
      "total_tokens": 1889,
      "input_cost": 0.00013687499999999998,
      "output_cost": 1.92e-05,
      "total_cost": 0.00015607499999999999
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C6+-+Agent+Memory.pdf",
    "question": "What is semantic long-term memory?",
    "gold_answer": "Memory that stores general facts, concepts, and stable user preferences.",
    "answer": "I don't know from the course materials.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf"
      ],
      "top1_doc": "C6+-+Agent+Memory.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 5
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 4
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 0
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 6
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 3
        }
      ]
    },
    "metrics": {
      "f1": 0.0,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.35460367798805237,
      "latency_seconds": 0.546871700003976,
      "input_tokens": 1810,
      "output_tokens": 11,
      "total_tokens": 1821,
      "input_cost": 0.00013575,
      "output_cost": 3.2999999999999993e-06,
      "total_cost": 0.00013905
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C6+-+Agent+Memory.pdf",
    "question": "Why don’t large context windows replace memory?",
    "gold_answer": "Because context windows are per-session and do not enable persistence across tasks or time.",
    "answer": "Large context windows do not replace memory because they are limited to a single session and lack true long-term understanding. They only carry over data within a single session.  Additionally, longer contexts can lead to slower responses and hallucinations.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C6+-+Agent+Memory.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C6+-+Agent+Memory.pdf",
        "C2+-+Large+Language+Models.pdf"
      ],
      "top1_doc": "C6+-+Agent+Memory.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 2
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 27
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 20
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 1
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 28
        }
      ]
    },
    "metrics": {
      "f1": 0.2978723404255319,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7615834474563599,
      "latency_seconds": 0.8232425000023795,
      "input_tokens": 1733,
      "output_tokens": 47,
      "total_tokens": 1780,
      "input_cost": 0.000129975,
      "output_cost": 1.4099999999999999e-05,
      "total_cost": 0.000144075
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C6+-+Agent+Memory.pdf",
    "question": "What is the role of a retriever in RAG?",
    "gold_answer": "The retriever finds semantically relevant information from external sources based on embeddings.",
    "answer": "In Retrieval Augmented Generation (RAG), the retriever fetches relevant documents or facts from a knowledge base. This information is then injected into the prompt to augment the LLM's response. The retriever helps the agent access and utilize information from a knowledge base.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C7+-+Finetuning.pdf",
        "C3+-+Introduction+to+Agents.pdf"
      ],
      "top1_doc": "C6+-+Agent+Memory.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 8
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 7
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 9
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 2
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 4
        }
      ]
    },
    "metrics": {
      "f1": 0.22727272727272727,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7097892761230469,
      "latency_seconds": 0.8195696000038879,
      "input_tokens": 1883,
      "output_tokens": 52,
      "total_tokens": 1935,
      "input_cost": 0.00014122499999999998,
      "output_cost": 1.5599999999999996e-05,
      "total_cost": 0.00015682499999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C7+-+Finetuning.pdf",
    "question": "What is the main purpose of fine-tuning?",
    "gold_answer": "To adapt a general LLM to specific tasks, domains, or behaviors using specialized training data.",
    "answer": "Fine-tuning bridges the gap between a general model's broad knowledge and the specific needs of a particular task or domain. It makes a model better at a particular problem by training it further using your own, task-specific data. This allows the model to perform specific tasks well, leveraging its comprehension of text data.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C7+-+Finetuning.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C7+-+Finetuning.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C7+-+Finetuning.pdf"
      ],
      "top1_doc": "C7+-+Finetuning.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 0
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 33
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 1
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 32
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 2
        }
      ]
    },
    "metrics": {
      "f1": 0.32142857142857145,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.732813835144043,
      "latency_seconds": 1.0059336999984225,
      "input_tokens": 1805,
      "output_tokens": 65,
      "total_tokens": 1870,
      "input_cost": 0.00013537499999999997,
      "output_cost": 1.95e-05,
      "total_cost": 0.00015487499999999996
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C7+-+Finetuning.pdf",
    "question": "Why is full fine-tuning expensive?",
    "gold_answer": "Because it updates all model parameters, requiring significant compute and memory.",
    "answer": "I don't know from the course materials.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C7+-+Finetuning.pdf",
        "C7+-+Finetuning.pdf",
        "C7+-+Finetuning.pdf",
        "C7+-+Finetuning.pdf",
        "C2+-+Large+Language+Models.pdf"
      ],
      "top1_doc": "C7+-+Finetuning.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 3
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 0
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 8
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 2
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 33
        }
      ]
    },
    "metrics": {
      "f1": 0.0,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.34704965353012085,
      "latency_seconds": 0.6071381000074325,
      "input_tokens": 1902,
      "output_tokens": 11,
      "total_tokens": 1913,
      "input_cost": 0.00014264999999999997,
      "output_cost": 3.2999999999999993e-06,
      "total_cost": 0.00014594999999999997
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C7+-+Finetuning.pdf",
    "question": "What does LoRA modify during fine-tuning?",
    "gold_answer": "LoRA inserts low-rank adapters to modify only a small subset of parameters efficiently.",
    "answer": "LoRA modifies small adapter matrices. These adapters are applied to selected layers, called \"Target Modules,\" to adjust them. Only these adapter weights get trained during fine-tuning.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C7+-+Finetuning.pdf",
        "C7+-+Finetuning.pdf",
        "C7+-+Finetuning.pdf",
        "C7+-+Finetuning.pdf",
        "C7+-+Finetuning.pdf"
      ],
      "top1_doc": "C7+-+Finetuning.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 6
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 8
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 7
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 0
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 9
        }
      ]
    },
    "metrics": {
      "f1": 0.27777777777777773,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.8213545680046082,
      "latency_seconds": 0.6668235999968601,
      "input_tokens": 1935,
      "output_tokens": 36,
      "total_tokens": 1971,
      "input_cost": 0.000145125,
      "output_cost": 1.0799999999999998e-05,
      "total_cost": 0.00015592499999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C7+-+Finetuning.pdf",
    "question": "What is one reason to prefer RAG over fine-tuning?",
    "gold_answer": "RAG integrates real-time external knowledge without updating model weights.",
    "answer": "RAG is preferred when an agent needs access to a lot of information, like user documents, long-term memory, or conversation history. It provides an efficient way of retrieving any piece of information from a knowledge base. Furthermore, RAG addresses the problems of outdated knowledge and hallucinations that LLMs can face.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C7+-+Finetuning.pdf",
        "C7+-+Finetuning.pdf",
        "C6+-+Agent+Memory.pdf",
        "C7+-+Finetuning.pdf",
        "C6+-+Agent+Memory.pdf"
      ],
      "top1_doc": "C7+-+Finetuning.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 2
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 1
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 8
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 10
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 9
        }
      ]
    },
    "metrics": {
      "f1": 0.0784313725490196,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7509296536445618,
      "latency_seconds": 0.7875089000008302,
      "input_tokens": 1673,
      "output_tokens": 61,
      "total_tokens": 1734,
      "input_cost": 0.000125475,
      "output_cost": 1.8299999999999998e-05,
      "total_cost": 0.000143775
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C7+-+Finetuning.pdf",
    "question": "What is the objective of evaluation after fine-tuning?",
    "gold_answer": "To ensure the fine-tuned model performs well on technical metrics and practical use cases.",
    "answer": "The lesson objectives state that you should be able to evaluate fine-tuned models using both technical and business metrics.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C7+-+Finetuning.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C7+-+Finetuning.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C7+-+Finetuning.pdf"
      ],
      "top1_doc": "C7+-+Finetuning.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 0
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 33
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 3
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 32
        },
        {
          "document": "C7+-+Finetuning.pdf",
          "chunk_id": 2
        }
      ]
    },
    "metrics": {
      "f1": 0.36363636363636365,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7568190693855286,
      "latency_seconds": 0.6255130000063218,
      "input_tokens": 1850,
      "output_tokens": 23,
      "total_tokens": 1873,
      "input_cost": 0.00013874999999999998,
      "output_cost": 6.899999999999999e-06,
      "total_cost": 0.00014565
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C8+-+Multi-Agent+Systems.pdf",
    "question": "Why are multi-agent systems needed for complex tasks?",
    "gold_answer": "Because complex tasks require decomposition into specialized subtasks handled by different agents.",
    "answer": "Multi-agent systems break complex tasks into manageable subtasks, similar to splitting a program into processes or threads. This makes building complex systems easier. Agentic workflows improve performance by guiding the model to handle one subtask at a time.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf"
      ],
      "top1_doc": "C8+-+Multi-Agent+Systems.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 1
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 0
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 2
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 3
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 9
        }
      ]
    },
    "metrics": {
      "f1": 0.2222222222222222,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7532078623771667,
      "latency_seconds": 0.692676400009077,
      "input_tokens": 1778,
      "output_tokens": 48,
      "total_tokens": 1826,
      "input_cost": 0.00013335,
      "output_cost": 1.44e-05,
      "total_cost": 0.00014774999999999999
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C8+-+Multi-Agent+Systems.pdf",
    "question": "What is an example of a natural pipeline that benefits from MAS?",
    "gold_answer": "ETL → analyze → generate → verify → publish.",
    "answer": "A task with a natural pipeline like ETL (extract, transform, load) -> analyze -> generate -> verify -> publish benefits from Multi-Agent Systems (MAS). This is because MAS can be designed to handle tasks with distinct sequential stages.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C1+-+Introduction+to+GenAI.pdf",
        "C5+-+Agent+Tools.pdf",
        "C1+-+Introduction+to+GenAI.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf"
      ],
      "top1_doc": "C1+-+Introduction+to+GenAI.pdf",
      "top1_matches_gold": false,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 23
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 16
        },
        {
          "document": "C1+-+Introduction+to+GenAI.pdf",
          "chunk_id": 1
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 2
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 0
        }
      ]
    },
    "metrics": {
      "f1": 0.27027027027027023,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.6358248591423035,
      "latency_seconds": 0.8319327999925008,
      "input_tokens": 1788,
      "output_tokens": 48,
      "total_tokens": 1836,
      "input_cost": 0.00013409999999999998,
      "output_cost": 1.44e-05,
      "total_cost": 0.00014849999999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C8+-+Multi-Agent+Systems.pdf",
    "question": "What is a reason to avoid multi-agent systems?",
    "gold_answer": "When orchestration complexity outweighs the benefits.",
    "answer": "You should avoid multi-agent systems when orchestration complexity outweighs the benefits or if latency/cost budgets are tight.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf"
      ],
      "top1_doc": "C8+-+Multi-Agent+Systems.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 2
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 1
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 3
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 0
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 9
        }
      ]
    },
    "metrics": {
      "f1": 0.5217391304347826,
      "exact_match_normalized": false,
      "contains_match": true,
      "is_correct": true,
      "semantic_similarity": 0.7244970202445984,
      "latency_seconds": 0.6359644000040134,
      "input_tokens": 1778,
      "output_tokens": 25,
      "total_tokens": 1803,
      "input_cost": 0.00013335,
      "output_cost": 7.499999999999999e-06,
      "total_cost": 0.00014084999999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C8+-+Multi-Agent+Systems.pdf",
    "question": "What is agent-to-agent communication used for?",
    "gold_answer": "To coordinate tasks and exchange intermediate results between agents.",
    "answer": "The Agent-to-Agent (A2A) protocol enables seamless interoperability within multi-agent systems. It allows a user-facing \"client\" agent to orchestrate and delegate tasks to specialized \"remote\" agents. The protocol is built on standard web technologies.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C8+-+Multi-Agent+Systems.pdf"
      ],
      "top1_doc": "C8+-+Multi-Agent+Systems.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 6
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 7
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 0
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 1
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 8
        }
      ]
    },
    "metrics": {
      "f1": 0.20512820512820512,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.6343104839324951,
      "latency_seconds": 0.6970812999934424,
      "input_tokens": 1848,
      "output_tokens": 55,
      "total_tokens": 1903,
      "input_cost": 0.0001386,
      "output_cost": 1.6499999999999998e-05,
      "total_cost": 0.0001551
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C8+-+Multi-Agent+Systems.pdf",
    "question": "Why might redundancy be used in MAS?",
    "gold_answer": "To improve reliability by having multiple agents independently produce or verify results.",
    "answer": "Redundancy can be used in Multi-Agent Systems. This is one of the reasons to use Multi-Agent Systems.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf"
      ],
      "top1_doc": "C8+-+Multi-Agent+Systems.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 0
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 3
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 2
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 1
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 4
        }
      ]
    },
    "metrics": {
      "f1": 0.07407407407407407,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.7129696607589722,
      "latency_seconds": 27.98669130000053,
      "input_tokens": 1790,
      "output_tokens": 25,
      "total_tokens": 1815,
      "input_cost": 0.00013424999999999998,
      "output_cost": 7.499999999999999e-06,
      "total_cost": 0.00014174999999999998
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C8+-+Multi-Agent+Systems.pdf",
    "question": "What problem arises if one agent tries to do everything?",
    "gold_answer": "Performance drops due to cognitive overload and lack of specialization.",
    "answer": "If one agent attempts to handle all tasks, such as designing, programming, and deployment for a multi-page website, the quality of the output would plummet. This is because LLMs struggle with complex inputs and agentic workflows improve performance by guiding the model to handle one subtask at a time.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C5+-+Agent+Tools.pdf",
        "C8+-+Multi-Agent+Systems.pdf",
        "C8+-+Multi-Agent+Systems.pdf"
      ],
      "top1_doc": "C8+-+Multi-Agent+Systems.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 1
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 0
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 9
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 4
        },
        {
          "document": "C8+-+Multi-Agent+Systems.pdf",
          "chunk_id": 2
        }
      ]
    },
    "metrics": {
      "f1": 0.15384615384615385,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.5478940010070801,
      "latency_seconds": 4.1471785999892745,
      "input_tokens": 1745,
      "output_tokens": 62,
      "total_tokens": 1807,
      "input_cost": 0.000130875,
      "output_cost": 1.8599999999999998e-05,
      "total_cost": 0.000149475
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C5+-+Agent+Tools.pdf",
    "question": "How do tools enhance safety in agent systems?",
    "gold_answer": "By constraining outputs and validating inputs, ensuring predictable and secure operations.",
    "answer": "Tools can enhance reliability and safety in agent systems. Adding tool schema validation, fallback options, retries, and tool metadata are solutions to tool misuse and failure recovery. Directing the agent's actions and boundaries and including forbidden actions also enhances safety.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C5+-+Agent+Tools.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C5+-+Agent+Tools.pdf",
        "C5+-+Agent+Tools.pdf",
        "C3+-+Introduction+to+Agents.pdf"
      ],
      "top1_doc": "C5+-+Agent+Tools.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 1
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 15
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 0
        },
        {
          "document": "C5+-+Agent+Tools.pdf",
          "chunk_id": 11
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 11
        }
      ]
    },
    "metrics": {
      "f1": 0.047619047619047616,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.5490654706954956,
      "latency_seconds": 0.8571321999916108,
      "input_tokens": 1843,
      "output_tokens": 50,
      "total_tokens": 1893,
      "input_cost": 0.00013822499999999999,
      "output_cost": 1.4999999999999999e-05,
      "total_cost": 0.000153225
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C6+-+Agent+Memory.pdf",
    "question": "What is episodic memory?",
    "gold_answer": "Memory of specific events or interactions that happened previously, including when and where they occurred.",
    "answer": "Episodic memory stores experiences. New information can be written to episodic memory. This information can later be retrieved back into working memory when needed for decision-making.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf",
        "C6+-+Agent+Memory.pdf"
      ],
      "top1_doc": "C6+-+Agent+Memory.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 6
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 3
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 5
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 26
        },
        {
          "document": "C6+-+Agent+Memory.pdf",
          "chunk_id": 1
        }
      ]
    },
    "metrics": {
      "f1": 0.1142857142857143,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.695720911026001,
      "latency_seconds": 0.7544888000120409,
      "input_tokens": 1738,
      "output_tokens": 33,
      "total_tokens": 1771,
      "input_cost": 0.00013035,
      "output_cost": 9.9e-06,
      "total_cost": 0.00014025
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
    "question": "How does top-p sampling work?",
    "gold_answer": "It restricts token selection to a subset of tokens whose cumulative probability mass is below a threshold p.",
    "answer": "Top-p sampling controls the diversity of responses by setting a threshold for the cumulative probability distribution of token choices. It considers a broader set of tokens for higher values, leading to more creative and varied responses.  The model chooses from words until their probabilities add up to p.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
        "C4+-+Agent+Personas++Thinking+Mechanisms.pdf"
      ],
      "top1_doc": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 2
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 3
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 34
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 4
        },
        {
          "document": "C4+-+Agent+Personas++Thinking+Mechanisms.pdf",
          "chunk_id": 11
        }
      ]
    },
    "metrics": {
      "f1": 0.3508771929824561,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.723906397819519,
      "latency_seconds": 0.7675403999892296,
      "input_tokens": 1734,
      "output_tokens": 56,
      "total_tokens": 1790,
      "input_cost": 0.00013005,
      "output_cost": 1.68e-05,
      "total_cost": 0.00014685
    }
  },
  {
    "provider": "gemini",
    "model": "gemini-2.0-flash-lite",
    "repeat_id": 0,
    "document": "C2+-+Large+Language+Models.pdf",
    "question": "What is one task LLMs can perform using only prompting without parameter updates?",
    "gold_answer": "In-context learning.",
    "answer": "LLMs can solve new tasks without gradient updates, just from prompts. This emergent behavior is a powerful capability that allows LLMs to perform various tasks.\n",
    "retrieval": {
      "top_k": 5,
      "retrieved_docs": [
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C3+-+Introduction+to+Agents.pdf",
        "C2+-+Large+Language+Models.pdf",
        "C2+-+Large+Language+Models.pdf"
      ],
      "top1_doc": "C2+-+Large+Language+Models.pdf",
      "top1_matches_gold": true,
      "any_match_in_topk": true,
      "chunks_used": [
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 4
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 5
        },
        {
          "document": "C3+-+Introduction+to+Agents.pdf",
          "chunk_id": 10
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 33
        },
        {
          "document": "C2+-+Large+Language+Models.pdf",
          "chunk_id": 3
        }
      ]
    },
    "metrics": {
      "f1": 0.0,
      "exact_match_normalized": false,
      "contains_match": false,
      "is_correct": false,
      "semantic_similarity": 0.4741150140762329,
      "latency_seconds": 0.7370299000031082,
      "input_tokens": 1783,
      "output_tokens": 31,
      "total_tokens": 1814,
      "input_cost": 0.00013372499999999998,
      "output_cost": 9.299999999999999e-06,
      "total_cost": 0.000143025
    }
  }
]